{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "2sEoa0dt3esW",
        "outputId": "338702a1-63ee-44a3-b57a-8ac1ef649b59"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.cloud.vision'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2ebad56d3171>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#!pip install google-cloud-vision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Google Cloud Vision API is installed and ready!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.cloud.vision'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "#!pip install google-cloud-vision\n",
        "\n",
        "import google.cloud.vision\n",
        "print(\"Google Cloud Vision API is installed and ready!\")\n",
        "\n",
        "import os\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"newhaiku.json\" ## u need to create ur own authentication key and link it here\n",
        "print(os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\"))\n",
        "\n",
        "from google.cloud import vision\n",
        "client = vision.ImageAnnotatorClient()\n",
        "print(\"Vision API client successfully initialized!\")\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "\n",
        "def analyze_image(image_path):\n",
        "    \"\"\"Analyzes an image for object labels and facial emotions using Google Cloud Vision API.\"\"\"\n",
        "\n",
        "    client = vision.ImageAnnotatorClient()\n",
        "\n",
        "    # Read image file\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        content = image_file.read()\n",
        "\n",
        "    image = vision.Image(content=content)\n",
        "\n",
        "    # Object detection\n",
        "    label_response = client.label_detection(image=image)\n",
        "    labels = label_response.label_annotations\n",
        "\n",
        "    print(\"\\nðŸŽ¯ Detected Labels:\")\n",
        "    for label in labels:\n",
        "        print(f\"- {label.description} (Confidence: {label.score:.2f})\")\n",
        "\n",
        "    # Face emotion detection\n",
        "    face_response = client.face_detection(image=image)\n",
        "    faces = face_response.face_annotations\n",
        "\n",
        "    if not faces:\n",
        "        print(\"\\nðŸ˜Š No faces detected.\")\n",
        "    else:\n",
        "        print(\"\\nðŸ˜Š Facial Emotion Analysis:\")\n",
        "        for i, face in enumerate(faces):\n",
        "            print(f\"\\nðŸ‘¤ Face {i+1}:\")\n",
        "            print(f\"   - Joy: {face.joy_likelihood}\")\n",
        "            print(f\"   - Sorrow: {face.sorrow_likelihood}\")\n",
        "            print(f\"   - Anger: {face.anger_likelihood}\")\n",
        "            print(f\"   - Surprise: {face.surprise_likelihood}\")\n",
        "\n",
        "# get image\n",
        "def analyze_image_labels(image_path):\n",
        "    \"\"\"Analyzes an image and returns a list of object labels.\"\"\"\n",
        "    client = vision.ImageAnnotatorClient()\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        content = image_file.read()\n",
        "    image = vision.Image(content=content)\n",
        "    label_response = client.label_detection(image=image)\n",
        "    labels = label_response.label_annotations\n",
        "    label_list = [label.description for label in labels]\n",
        "    return label_list\n",
        "\n",
        "\n",
        "# Haiku Generation\n",
        "def generate_haiku_ai(labels, project_id, location, endpoint_id):\n",
        "    \"\"\"Generates a haiku using a Google Cloud Vertex AI model.\"\"\"\n",
        "    aiplatform.init(project=project_id, location=location)\n",
        "    endpoint = aiplatform.Endpoint(endpoint_name=f\"projects/{project_id}/locations/{location}/endpoints/{endpoint_id}\")\n",
        "    prompt = f\"Write a haiku about: {', '.join(labels)}. Be creative and follow the 5-7-5 syllable structure.\"\n",
        "    instances = [{\"prompt\": prompt}]\n",
        "    prediction = endpoint.predict(instances=instances)\n",
        "    haiku = prediction.predictions[0][\"content\"]\n",
        "    return haiku.strip()\n",
        "\n",
        "# Example usage (replace with your values)\n",
        "image_path = \"ithaca.jpg\"\n",
        "project_id = \"compact-marker-451921-b1\"\n",
        "location = \"us-central1\"\n",
        "endpoint_id = \"YOUR_ENDPOINT_ID\" # Replace with your endpoint ID\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# For Ithaca.jpg image\n",
        "# Extract just the labels\n",
        "labels = analyze_image_labels(\"ithaca.jpg\")\n",
        "print(\"\\nExtracted Labels:\", labels)\n",
        "\n",
        "# Generate and print the haiku\n",
        "try:\n",
        "    haiku = generate_haiku_ai(labels, project_id, location, endpoint_id)\n",
        "    print(\"\\nGenerated Haiku (AI):\")\n",
        "    print(haiku)\n",
        "except Exception as e:\n",
        "    print(f\"Error generating haiku: {e}\")\n",
        "    print(\"Please ensure you have set up Vertex AI correctly and have a model deployed.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import vertexai\n",
        "from google.cloud import vision\n",
        "from vertexai.language_models import TextGenerationModel\n",
        "\n",
        "# Set the path to your service account JSON file\n",
        "SERVICE_ACCOUNT_FILE = \"newhaiku.json\"\n",
        "\n",
        "# Set the GOOGLE_APPLICATION_CREDENTIALS environment variable\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = SERVICE_ACCOUNT_FILE\n",
        "\n",
        "# Project and Location\n",
        "PROJECT_ID = \"compact-marker-451921-b1\"\n",
        "LOCATION = \"us-central1\"\n",
        "\n",
        "# Initialize Vertex AI\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "# Image Path\n",
        "image_path = \"ithaca.jpg\"\n",
        "\n",
        "# Vision AI Description\n",
        "def describe_image(image_path):\n",
        "    client = vision.ImageAnnotatorClient()\n",
        "    with open(image_path, 'rb') as image_file:\n",
        "        content = image_file.read()\n",
        "    image = vision.Image(content=content)\n",
        "    response = client.annotate_image({\n",
        "        'image': image,\n",
        "        'features': [{'type_': vision.Feature.Type.LABEL_DETECTION}],\n",
        "    })\n",
        "    labels = [label.description for label in response.label_annotations]\n",
        "    return \", \".join(labels)\n",
        "\n",
        "image_description = describe_image(image_path)\n",
        "print(f\"Image Description: {image_description}\")\n",
        "\n",
        "# Text Bison Haiku Generation\n",
        "def generate_haiku(image_description):\n",
        "    model = TextGenerationModel.from_pretrained(\"text-bison\")\n",
        "    prompt = f\"\"\"\n",
        "    Create a haiku based on the following image description:\n",
        "    {image_description}\n",
        "    Haiku:\n",
        "    \"\"\"\n",
        "    response = model.predict(\n",
        "        prompt,\n",
        "        temperature=0.7,\n",
        "        max_output_tokens=256,\n",
        "        top_p=0.8,\n",
        "        top_k=40,\n",
        "    )\n",
        "    return response.text\n",
        "\n",
        "haiku = generate_haiku(image_description)\n",
        "print(f\"Generated Haiku:\\n{haiku}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "rema6_5l1mEf",
        "outputId": "c44f7ecc-54be-4a89-df02-b6a3216729c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Description: City, Residential area, Urban area, Neighbourhood, Landscape, Roof, Bird's-eye view, Human settlement, Urban design, Suburb\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadRequest",
          "evalue": "400 POST https://us-central1-aiplatform.googleapis.com/v1/projects/compact-marker-451921-b1/locations/us-central1/publishers/google/models/text-bison@002:predict?%24alt=json%3Benum-encoding%3Dint: Project `965935594995` is not allowed to use Publisher Model `projects/compact-marker-451921-b1/locations/us-central1/publishers/google/models/text-bison@002`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-e7fbf758aa66>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mhaiku\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_haiku\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Generated Haiku:\\n{haiku}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-e7fbf758aa66>\u001b[0m in \u001b[0;36mgenerate_haiku\u001b[0;34m(image_description)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mHaiku\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \"\"\"\n\u001b[0;32m---> 46\u001b[0;31m     response = model.predict(\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.11/site-packages/vertexai/language_models/_language_models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, prompt, max_output_tokens, temperature, top_k, top_p, stop_sequences, candidate_count, grounding_source, logprobs, presence_penalty, frequency_penalty, logit_bias, seed)\u001b[0m\n\u001b[1;32m   1415\u001b[0m         )\n\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1417\u001b[0;31m         prediction_response = self._endpoint.predict(\n\u001b[0m\u001b[1;32m   1418\u001b[0m             \u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprediction_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.11/site-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, instances, parameters, timeout, use_raw_predict, use_dedicated_endpoint)\u001b[0m\n\u001b[1;32m   2424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2425\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2426\u001b[0;31m             prediction_response = self._prediction_client.predict(\n\u001b[0m\u001b[1;32m   2427\u001b[0m                 \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2428\u001b[0m                 \u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.11/site-packages/google/cloud/aiplatform_v1/services/prediction_service/client.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, request, endpoint, instances, parameters, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    967\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.11/site-packages/google/cloud/aiplatform_v1/services/prediction_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1700\u001b[0m             \u001b[0;31m# subclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mcore_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m             \u001b[0;31m# Return the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadRequest\u001b[0m: 400 POST https://us-central1-aiplatform.googleapis.com/v1/projects/compact-marker-451921-b1/locations/us-central1/publishers/google/models/text-bison@002:predict?%24alt=json%3Benum-encoding%3Dint: Project `965935594995` is not allowed to use Publisher Model `projects/compact-marker-451921-b1/locations/us-central1/publishers/google/models/text-bison@002`"
          ]
        }
      ]
    },
    {
      "source": [
        "import os\n",
        "import vertexai\n",
        "from google.cloud import vision\n",
        "from vertexai.language_models import TextGenerationModel\n",
        "\n",
        "# Set the path to your service account JSON file\n",
        "SERVICE_ACCOUNT_FILE = \"newhaiku.json\"\n",
        "\n",
        "# Set the GOOGLE_APPLICATION_CREDENTIALS environment variable\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = SERVICE_ACCOUNT_FILE\n",
        "\n",
        "# Project and Location\n",
        "PROJECT_ID = \"compact-marker-451921-b1\"\n",
        "LOCATION = \"us-central1\"\n",
        "\n",
        "# Initialize Vertex AI\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
        "\n",
        "# Image Path\n",
        "image_path = \"ithaca.jpg\"\n",
        "\n",
        "# Vision AI Description\n",
        "def describe_image(image_path):\n",
        "    client = vision.ImageAnnotatorClient()\n",
        "    with open(image_path, 'rb') as image_file:\n",
        "        content = image_file.read()\n",
        "    image = vision.Image(content=content)\n",
        "    response = client.annotate_image({\n",
        "        'image': image,\n",
        "        'features': [{'type_': vision.Feature.Type.LABEL_DETECTION}],\n",
        "    })\n",
        "    labels = [label.description for label in response.label_annotations]\n",
        "    return \", \".join(labels)\n",
        "\n",
        "image_description = describe_image(image_path)\n",
        "print(f\"Image Description: {image_description}\")\n",
        "\n",
        "# Text Bison Haiku Generation\n",
        "def generate_haiku(image_description):\n",
        "    # Pass project to from_pretrained\n",
        "    model = TextGenerationModel.from_pretrained(\"text-bison\", project=PROJECT_ID)\n",
        "    prompt = f\"\"\"\n",
        "    Create a haiku based on the following image description:\n",
        "    {image_description}\n",
        "    Haiku:\n",
        "    \"\"\"\n",
        "    response = model.predict(\n",
        "        prompt,\n",
        "        temperature=0.7,\n",
        "        max_output_tokens=256,\n",
        "        top_p=0.8,\n",
        "        top_k=40,\n",
        "    )\n",
        "    return response.text\n",
        "\n",
        "haiku = generate_haiku(image_description)\n",
        "print(f\"Generated Haiku:\\n{haiku}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "AHF5jlhk3RL0",
        "outputId": "dc3baf6d-32fc-4c41-96ed-8b9bdaa317b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image Description: City, Residential area, Urban area, Neighbourhood, Landscape, Roof, Bird's-eye view, Human settlement, Urban design, Suburb\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "_ModelGardenModel.from_pretrained() got an unexpected keyword argument 'project'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-fd0f1d73b30f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mhaiku\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_haiku\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Generated Haiku:\\n{haiku}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-fd0f1d73b30f>\u001b[0m in \u001b[0;36mgenerate_haiku\u001b[0;34m(image_description)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_haiku\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Pass project to from_pretrained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextGenerationModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text-bison\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPROJECT_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     prompt = f\"\"\"\n\u001b[1;32m     43\u001b[0m     \u001b[0mCreate\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhaiku\u001b[0m \u001b[0mbased\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfollowing\u001b[0m \u001b[0mimage\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: _ModelGardenModel.from_pretrained() got an unexpected keyword argument 'project'"
          ]
        }
      ]
    }
  ]
}